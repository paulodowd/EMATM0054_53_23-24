{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9DspfiSOmMX4kTf4NxOIN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulodowd/EMATM0054_53_23-24/blob/main/Project_Idea_2_Leader_Follower.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Leader-Follower"
      ],
      "metadata": {
        "id": "iIKRvPdvCpPt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observation\n",
        "\n",
        "The 3Pi+ bumpers and line sensors operate by reading reflected infra-red (IR) light.  It is possible to configure the 3Pi+ robot to enable or disable the emission of IR light.  By removing the plastic body shell of a robot, it should be possible to emit IR light from one robot, and for a second robot to detect this source by using the bump sensors and/or line sensors.  Furthermore, if the emitting robot is moving, the second robot should be able to follow it (track angle and distance), by looking at the strength of the received signal and/or the difference between left and right sensors.\n",
        "\n",
        "<p align=\"center\">\n",
        "<img width=\"500\" src=\"https://github.com/paulodowd/EMATM0054_53_23-24/blob/main/Images/leader_follower.png?raw=true\">\n",
        "</p>\n",
        "\n",
        "# Hypothesis\n",
        "\n",
        "In this scenario, there are many potential factors that will influence performance.  These include:\n",
        "\n",
        "- **Sensor reading operation**: There are two ways to read the line sensors and bump sensors - either by measuring elapsed time, or by an ADC read.  The ADC read is quick and time-constant, but has poorer resolution.  In contrast, using elapsed time means that sensor reads can take a different amount of time, but the resolution is better.  Measuring elapsed time is likely to be a significant problem if the leader is relatively far away, because there will be a weak IR source to discharge the sensor capacitor (e.g., it could take a long time to perform a sensor read) - so an ADC read of the bumpers may be more appropriate.  However, the increased resolution of the elapsed time technique may be important for determining the angle of the leader relative to the follower via the line sensors.\n",
        "- **Difference in relative position of line sensors and bump sensors**: the bump sensors are close together, so likely provide less information for determining the angle between leader and follower robot. The line sensors are more spread out, and so a larger difference in readings is likely when the leader robot is misaligned with the follower.\n",
        "- **Difference in sensor orientation**: the line sensors face downward, and so they will likely provide a weaker reading of IR overall.  In contrast, the bump sensors face forwards and so they would likely provide a stronger reading of the IR.  Therefore, the bump sensors are likely to provide a more reliable measurement of the distance between leader and follower.\n",
        "- **Distance trade-off:** Because the line sensors face downward they are likely to operate best at a short range, relative to the bump sensors.  However, the distance between robots is likely to effect how well the system can avoid losing the follower or avoiding collisions.  For example, a larger distance between robots might provide \"more time to react\".  Therefore, there will be an optimum distance to set the follower to maintain from the leader, that balance both the determination of angle to the leader, and a \"safe distance\" to follow.\n",
        "- **Combination of sensors**: The 3Pi+ has 5 line sensors, and 2 bump sensors. These may have different utility as described above.  We predict that there may be an optimum scheme to combine information from these different sources.  It may be that the outer most line sensors offer utility for extreme following behaviours - e.g., if the leader turns suddenly.\n",
        "\n",
        "# Measurements & Results\n",
        "\n",
        "In these experiments, we anticipate using:\n",
        "- kinematics & odometry, to capture how the robots are travelling (e.g. x and y translation) and the quality of their motion (e.g., oscillation in theta).  We will be able to compare the travel of leader and follower to determine a measurement of following error.\n",
        "- wheel speed, PID feedback: we could use wheel speed and speed control to understand the quality of the robot motion, or overall following behaviour.\n",
        "- sensor activation: we can capture the sensor activation (continuous values) of the follower to understand the consistency and response of the following behaviour.\n",
        "- robot stopping position: by controlling the distance, path and travel time of the leader, we can evaluate a final measure of performance by inspecting the final location of the follower.\n",
        "\n",
        "# Method\n",
        "\n",
        "This system could be evaluated in many scenarios, and with a high degree of variation.  We will therefore take an approach to first of all understand the feasibility of the hypotheses, and then select the most interesting aspects to pursue in depth.\n",
        "\n",
        "We will conduct some preliminary studies to understand:\n",
        "- plot the sensor response of the bump sensors and line sensors with respect to the leader IR emission.  We will utilise these responses to identify what should be a good distance to maintain between robots, and the limits of misalignment.\n",
        "- how well a distance can be controlled between a leader and follower.  This will use PID to control only forward/backward motion of the follower.\n",
        "- how well angle of the follower can be controlled relative to the leader.  This wil use PID to control only the rotation of the follower.  \n",
        "\n",
        "We will then conduct experiments that combine both rotation and foward/backward control of the follower, with respect to the leader.  Depending on the project progress, we will aim to progressively evalaute:\n",
        "- straight line travel of the leader.\n",
        "- straight line travel of the leader, but with a scheme of velocity changes.\n",
        "- curved travel of the leader, using prescribed wheel speeds of the leader to create curves of fixed radii.\n",
        "\n",
        "If time permits, we may implement an improvement to the sensor processing or motion control, compared against the prior evaluation(s) made."
      ],
      "metadata": {
        "id": "cn1fws_f6CAR"
      }
    }
  ]
}